{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swissgrid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = swissgrid.grid_data.iloc[:,0].fillna(method='bfill')\n",
    "SAMPS_DAY = 24*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('data/weather_data_filtered.csv')\n",
    "weather['timestamp'] = pd.to_datetime(weather['utc_timestamp'])\n",
    "weather = weather[['timestamp', 'CH_temperature']].set_index('timestamp').sort_index()\n",
    "weather = weather.resample('1 H').first()\n",
    "weather = weather.tz_localize(None)\n",
    "weather = weather.resample('15 T').interpolate('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the two sequences\n",
    "ts = ts[:weather.index[-1]]\n",
    "weather = weather[ts.index[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ts.index\n",
    "# special days\n",
    "def get_holy(prov):\n",
    "    h = holidays.Switzerland(prov=prov)\n",
    "    return [day in h for day in days]\n",
    "holidays_cantons = pd.DataFrame(data = {prov:get_holy(prov) for prov in holidays.Switzerland.PROVINCES},\n",
    "             index = days)\n",
    "#add sundays (hurts MSE)\n",
    "# holidays_cantons = (holidays_cantons.T | (holidays_cantons.index.dayofweek == 6)).T\n",
    "\n",
    "cantons = pd.read_csv('data/cantons.csv').set_index('Code')\n",
    "#magic trick\n",
    "cantons['Population'] = cantons['Population'].str.extract('([^\\[]*)').iloc[:,0].str.split(',').str.join('').astype(np.intp)\n",
    "\n",
    "holiday_pop = holidays_cantons*cantons['Population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoregressive part\n",
    "\n",
    "The consumption $L_{hd}$ today at day $d$ and hour $h$ depends on $L_{h-1d}$, $L_{hd-1}$, $L_{hd-7}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ts_regressor(ts, fourier_order=4):\n",
    "    #interact annual pattern like (6)\n",
    "    week_lag_idx = np.arange(ts.size-SAMPS_DAY*7)\n",
    "    t = ((\n",
    "        ts.index[SAMPS_DAY*7:ts.size] - pd.datetime(year=ts.index[0].year, month=1, day=1)\n",
    "    ).total_seconds()//(60*24*60/SAMPS_DAY)).astype(np.intp)\n",
    "    samps_year = SAMPS_DAY*7*52\n",
    "    sins =  np.array([np.sin(2*q*np.pi*(t/samps_year)) for q in range(1, fourier_order+1)]).T\n",
    "    cosins =np.array([np.cos(2*q*np.pi*(t/samps_year)) for q in range(1, fourier_order+1)]).T\n",
    "    week_lagged_reg = ts.values[week_lag_idx,None]*np.hstack([np.ones((week_lag_idx.size,1)), sins, cosins])\n",
    "    \n",
    "    #interact daily indicators with daily lag (5)\n",
    "    week_day = ts.index[SAMPS_DAY*7:ts.size].dayofweek\n",
    "    I = np.eye(7)\n",
    "    week_day_indicators = np.array([I[i] for i in week_day])\n",
    "    day_lag_idx = np.arange(SAMPS_DAY*6, ts.size-SAMPS_DAY)\n",
    "    day_lagged_reg = ts.values[day_lag_idx,None]*week_day_indicators\n",
    "    \n",
    "    # hourly lag regressor (7)\n",
    "    hour_lag_idx = np.arange(SAMPS_DAY*7 - 1, ts.size-1)\n",
    "    hour_lagged_reg = ts.values[hour_lag_idx][:,None]\n",
    "    \n",
    "    #temperature\n",
    "    weather_reg = weather.values[SAMPS_DAY*7:ts.size]\n",
    "    \n",
    "    #special days\n",
    "    holiday_reg = holiday_pop.sum(axis=1).values[SAMPS_DAY*7:ts.size, None]\n",
    "    holiday_lagged_reg = holiday_pop.sum(axis=1).values[:ts.size - SAMPS_DAY*7,None]\n",
    "    \n",
    "    return np.hstack(\n",
    "        [\n",
    "            week_lagged_reg,\n",
    "            day_lagged_reg,\n",
    "            hour_lagged_reg,\n",
    "            weather_reg,\n",
    "            holiday_reg,\n",
    "            holiday_lagged_reg\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = build_ts_regressor(ts)\n",
    "# lr = LinearRegression().fit(reg, ts.values[7*SAMPS_DAY:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.OLS(ts.values[7*SAMPS_DAY:], reg)\n",
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   1.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>5.744e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 03 Jun 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:39:38</td>     <th>  Log-Likelihood:    </th> <td>-3.2412e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>279835</td>      <th>  AIC:               </th>  <td>6.482e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>279815</td>      <th>  BIC:               </th>  <td>6.483e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    20</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>    0.0637</td> <td>    0.001</td> <td>  126.311</td> <td> 0.000</td> <td>    0.063</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>   -0.0027</td> <td> 5.55e-05</td> <td>  -49.257</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td> 1.128e-05</td> <td> 4.32e-05</td> <td>    0.261</td> <td> 0.794</td> <td>-7.34e-05</td> <td> 9.59e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>    0.0002</td> <td> 4.29e-05</td> <td>    4.240</td> <td> 0.000</td> <td> 9.78e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>    0.0002</td> <td> 4.22e-05</td> <td>    3.937</td> <td> 0.000</td> <td> 8.34e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>   -0.0034</td> <td> 8.38e-05</td> <td>  -40.314</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td> 8.862e-06</td> <td> 4.25e-05</td> <td>    0.208</td> <td> 0.835</td> <td>-7.45e-05</td> <td> 9.22e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>    0.0002</td> <td> 4.32e-05</td> <td>    4.573</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>   -0.0006</td> <td> 4.26e-05</td> <td>  -13.080</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>    0.0363</td> <td>    0.000</td> <td>   73.233</td> <td> 0.000</td> <td>    0.035</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>    0.0302</td> <td>    0.000</td> <td>   73.334</td> <td> 0.000</td> <td>    0.029</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>    0.0296</td> <td>    0.000</td> <td>   73.273</td> <td> 0.000</td> <td>    0.029</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>    0.0295</td> <td>    0.000</td> <td>   73.350</td> <td> 0.000</td> <td>    0.029</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>    0.0293</td> <td>    0.000</td> <td>   73.465</td> <td> 0.000</td> <td>    0.028</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th> <td>    0.0258</td> <td>    0.000</td> <td>   73.028</td> <td> 0.000</td> <td>    0.025</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th> <td>    0.0278</td> <td>    0.000</td> <td>   73.502</td> <td> 0.000</td> <td>    0.027</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th> <td>    0.9099</td> <td>    0.001</td> <td> 1600.969</td> <td> 0.000</td> <td>    0.909</td> <td>    0.911</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th> <td> -595.4113</td> <td>   11.870</td> <td>  -50.161</td> <td> 0.000</td> <td> -618.676</td> <td> -572.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th> <td>   -0.0024</td> <td> 3.92e-05</td> <td>  -60.627</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th> <td>    0.0021</td> <td> 3.93e-05</td> <td>   53.753</td> <td> 0.000</td> <td>    0.002</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2479.383</td> <th>  Durbin-Watson:     </th> <td>   1.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2582.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.219</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.172</td>  <th>  Cond. No.          </th> <td>6.02e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.02e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 5.744e+07\n",
       "Date:                Mon, 03 Jun 2019   Prob (F-statistic):               0.00\n",
       "Time:                        21:39:38   Log-Likelihood:            -3.2412e+06\n",
       "No. Observations:              279835   AIC:                         6.482e+06\n",
       "Df Residuals:                  279815   BIC:                         6.483e+06\n",
       "Df Model:                          20                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0637      0.001    126.311      0.000       0.063       0.065\n",
       "x2            -0.0027   5.55e-05    -49.257      0.000      -0.003      -0.003\n",
       "x3          1.128e-05   4.32e-05      0.261      0.794   -7.34e-05    9.59e-05\n",
       "x4             0.0002   4.29e-05      4.240      0.000    9.78e-05       0.000\n",
       "x5             0.0002   4.22e-05      3.937      0.000    8.34e-05       0.000\n",
       "x6            -0.0034   8.38e-05    -40.314      0.000      -0.004      -0.003\n",
       "x7          8.862e-06   4.25e-05      0.208      0.835   -7.45e-05    9.22e-05\n",
       "x8             0.0002   4.32e-05      4.573      0.000       0.000       0.000\n",
       "x9            -0.0006   4.26e-05    -13.080      0.000      -0.001      -0.000\n",
       "x10            0.0363      0.000     73.233      0.000       0.035       0.037\n",
       "x11            0.0302      0.000     73.334      0.000       0.029       0.031\n",
       "x12            0.0296      0.000     73.273      0.000       0.029       0.030\n",
       "x13            0.0295      0.000     73.350      0.000       0.029       0.030\n",
       "x14            0.0293      0.000     73.465      0.000       0.028       0.030\n",
       "x15            0.0258      0.000     73.028      0.000       0.025       0.026\n",
       "x16            0.0278      0.000     73.502      0.000       0.027       0.029\n",
       "x17            0.9099      0.001   1600.969      0.000       0.909       0.911\n",
       "x18         -595.4113     11.870    -50.161      0.000    -618.676    -572.146\n",
       "x19           -0.0024   3.92e-05    -60.627      0.000      -0.002      -0.002\n",
       "x20            0.0021   3.93e-05     53.753      0.000       0.002       0.002\n",
       "==============================================================================\n",
       "Omnibus:                     2479.383   Durbin-Watson:                   1.085\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2582.538\n",
       "Skew:                           0.219   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.172   Cond. No.                     6.02e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.02e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013428251107830377"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE_triv = np.mean(np.abs((ts.values[7*SAMPS_DAY-1:-1] - ts.values[7*SAMPS_DAY:]))/ts.values[7*SAMPS_DAY:])\n",
    "MAPE_triv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012889730248821443"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE = np.mean(np.abs((res.predict(reg) - ts.values[7*SAMPS_DAY:]))/ts.values[7*SAMPS_DAY:])\n",
    "MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average part\n",
    "\n",
    "We can now add a moving average component to the mix and see if our forecasting imporves. The moving average takes into account previous hour errors and previous week error.\n",
    "The estimation is done by applying the ordinary linear model, and treating residuals as estimated innovations, and iterating the least square estimation, and innovation estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.012891331041182683\n",
      "1 0.006111266152547367\n",
      "2 0.012204949234665176\n",
      "3 0.007349233560088345\n",
      "4 0.011653519642260943\n",
      "5 0.008100415360184365\n",
      "6 0.011247288427572057\n",
      "7 0.008535613591909425\n",
      "8 0.010994334348652945\n",
      "9 0.00879621386684479\n",
      "10 0.0108397184426317\n",
      "11 0.008959235732781849\n",
      "12 0.010722813642729869\n",
      "13 0.009094050269061262\n",
      "14 0.010618749471466123\n",
      "15 0.009224237783588152\n",
      "16 0.010516031483327972\n",
      "17 0.009345019998851564\n",
      "18 0.010419877623092945\n",
      "19 0.009449423842067923\n",
      "20 0.010336393871360908\n",
      "21 0.009532049704080715\n",
      "22 0.010268287147299578\n",
      "23 0.009595802317127455\n",
      "24 0.0102164300068617\n",
      "25 0.009646227591525561\n",
      "26 0.010172747477543294\n",
      "27 0.009687317717169417\n",
      "28 0.010135573150687001\n",
      "29 0.009722403174537259\n",
      "30 0.010104606843200139\n",
      "31 0.009753236236578304\n",
      "32 0.01007674929078985\n",
      "33 0.009779669951064026\n",
      "34 0.010052395481345351\n",
      "35 0.009803158257182277\n",
      "36 0.010032054370681151\n",
      "37 0.009822608543991865\n",
      "38 0.01001465879078973\n",
      "39 0.009838909388565017\n",
      "40 0.01000017768294308\n",
      "41 0.00985299458977985\n",
      "42 0.009988502276119532\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-87fc7ec90d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0meps_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps_reg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_reg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                     hasattr(self, 'rank')):\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv_wexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingular_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpinv_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                 self.normalized_cov_params = np.dot(\n\u001b[1;32m    275\u001b[0m                     self.pinv_wexog, np.transpose(self.pinv_wexog))\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/tools/tools.py\u001b[0m in \u001b[0;36mpinv_extended\u001b[0;34m(X, rcond)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0ms_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reg = build_ts_regressor(ts)\n",
    "eps = np.zeros_like(ts.values[7*SAMPS_DAY:])\n",
    "# we drop an additional leading week so the least squares estimation is done\n",
    "# with all the estimated epsilons, previous week before included.\n",
    "for c in range(30):\n",
    "    eps_reg = np.hstack([eps[:-7*SAMPS_DAY,None], eps[6*SAMPS_DAY:-SAMPS_DAY,None]])\n",
    "    mod = sm.OLS(exog=np.hstack([reg[7*SAMPS_DAY:],eps_reg]), endog=ts.values[14*SAMPS_DAY:])\n",
    "    res = mod.fit()\n",
    "    eps = ts.values[7*SAMPS_DAY:] - res.predict(np.hstack([reg, np.vstack([np.zeros([7*SAMPS_DAY,eps_reg.shape[1]]), eps_reg])]))\n",
    "    print(c, np.mean(np.abs(eps[7*SAMPS_DAY:]/ts.values[14*SAMPS_DAY:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   1.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>8.693e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 03 Jun 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:44:32</td>     <th>  Log-Likelihood:    </th> <td>-3.1618e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>279163</td>      <th>  AIC:               </th>  <td>6.324e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>279141</td>      <th>  BIC:               </th>  <td>6.324e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    22</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>    0.0411</td> <td>    0.000</td> <td>  101.944</td> <td> 0.000</td> <td>    0.040</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>   -0.0017</td> <td> 4.31e-05</td> <td>  -40.564</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td> 3.692e-05</td> <td> 3.34e-05</td> <td>    1.104</td> <td> 0.269</td> <td>-2.86e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td> 8.563e-05</td> <td> 3.32e-05</td> <td>    2.578</td> <td> 0.010</td> <td> 2.05e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>  8.67e-05</td> <td> 3.27e-05</td> <td>    2.654</td> <td> 0.008</td> <td> 2.27e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>   -0.0020</td> <td>  6.5e-05</td> <td>  -30.914</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>-1.728e-05</td> <td> 3.29e-05</td> <td>   -0.524</td> <td> 0.600</td> <td>-8.18e-05</td> <td> 4.73e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td> 8.429e-05</td> <td> 3.35e-05</td> <td>    2.518</td> <td> 0.012</td> <td> 1.87e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>   -0.0004</td> <td> 3.31e-05</td> <td>  -11.386</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>    0.0222</td> <td>    0.000</td> <td>   57.135</td> <td> 0.000</td> <td>    0.021</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>    0.0182</td> <td>    0.000</td> <td>   56.241</td> <td> 0.000</td> <td>    0.018</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>    0.0180</td> <td>    0.000</td> <td>   56.943</td> <td> 0.000</td> <td>    0.017</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>    0.0179</td> <td>    0.000</td> <td>   57.001</td> <td> 0.000</td> <td>    0.017</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>    0.0178</td> <td>    0.000</td> <td>   56.945</td> <td> 0.000</td> <td>    0.017</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th> <td>    0.0155</td> <td>    0.000</td> <td>   56.220</td> <td> 0.000</td> <td>    0.015</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th> <td>    0.0170</td> <td>    0.000</td> <td>   57.203</td> <td> 0.000</td> <td>    0.016</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th> <td>    0.9428</td> <td>    0.000</td> <td> 2099.063</td> <td> 0.000</td> <td>    0.942</td> <td>    0.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th> <td> -359.3557</td> <td>    9.225</td> <td>  -38.954</td> <td> 0.000</td> <td> -377.437</td> <td> -341.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th> <td>   -0.0016</td> <td> 3.04e-05</td> <td>  -53.616</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th> <td>    0.0015</td> <td> 3.08e-05</td> <td>   47.380</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th> <td>    0.5111</td> <td>    0.003</td> <td>  202.641</td> <td> 0.000</td> <td>    0.506</td> <td>    0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th> <td>    0.4196</td> <td>    0.002</td> <td>  168.105</td> <td> 0.000</td> <td>    0.415</td> <td>    0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3410.758</td> <th>  Durbin-Watson:     </th> <td>   1.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4178.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.202</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.442</td>  <th>  Cond. No.          </th> <td>6.03e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.03e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 8.693e+07\n",
       "Date:                Mon, 03 Jun 2019   Prob (F-statistic):               0.00\n",
       "Time:                        21:44:32   Log-Likelihood:            -3.1618e+06\n",
       "No. Observations:              279163   AIC:                         6.324e+06\n",
       "Df Residuals:                  279141   BIC:                         6.324e+06\n",
       "Df Model:                          22                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0411      0.000    101.944      0.000       0.040       0.042\n",
       "x2            -0.0017   4.31e-05    -40.564      0.000      -0.002      -0.002\n",
       "x3          3.692e-05   3.34e-05      1.104      0.269   -2.86e-05       0.000\n",
       "x4          8.563e-05   3.32e-05      2.578      0.010    2.05e-05       0.000\n",
       "x5           8.67e-05   3.27e-05      2.654      0.008    2.27e-05       0.000\n",
       "x6            -0.0020    6.5e-05    -30.914      0.000      -0.002      -0.002\n",
       "x7         -1.728e-05   3.29e-05     -0.524      0.600   -8.18e-05    4.73e-05\n",
       "x8          8.429e-05   3.35e-05      2.518      0.012    1.87e-05       0.000\n",
       "x9            -0.0004   3.31e-05    -11.386      0.000      -0.000      -0.000\n",
       "x10            0.0222      0.000     57.135      0.000       0.021       0.023\n",
       "x11            0.0182      0.000     56.241      0.000       0.018       0.019\n",
       "x12            0.0180      0.000     56.943      0.000       0.017       0.019\n",
       "x13            0.0179      0.000     57.001      0.000       0.017       0.019\n",
       "x14            0.0178      0.000     56.945      0.000       0.017       0.018\n",
       "x15            0.0155      0.000     56.220      0.000       0.015       0.016\n",
       "x16            0.0170      0.000     57.203      0.000       0.016       0.018\n",
       "x17            0.9428      0.000   2099.063      0.000       0.942       0.944\n",
       "x18         -359.3557      9.225    -38.954      0.000    -377.437    -341.275\n",
       "x19           -0.0016   3.04e-05    -53.616      0.000      -0.002      -0.002\n",
       "x20            0.0015   3.08e-05     47.380      0.000       0.001       0.002\n",
       "x21            0.5111      0.003    202.641      0.000       0.506       0.516\n",
       "x22            0.4196      0.002    168.105      0.000       0.415       0.425\n",
       "==============================================================================\n",
       "Omnibus:                     3410.758   Durbin-Watson:                   1.538\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4178.395\n",
       "Skew:                           0.202   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.442   Cond. No.                     6.03e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.03e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Equations\n",
    "\n",
    "By changing the single regression into 96 individual parameter sets, one for each daily time, we are back to the multiple equations setting described in Clements, Hurn and Li."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.004463099639687451\n",
      "10 0.0043431666931691305\n",
      "20 0.0043424927367846184\n",
      "30 0.004342451186844226\n",
      "40 0.0043424485292942305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-938fe0a95600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdaily_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps_reg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdaily_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 ),\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mendog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdaily_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             ).fit()\n\u001b[1;32m     14\u001b[0m         \u001b[0meps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdaily_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdaily_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mSAMPS_DAY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m                  **kwargs):\n\u001b[1;32m    816\u001b[0m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[0;32m--> 817\u001b[0;31m                                   hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"weights\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[0;32m--> 663\u001b[0;31m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \"\"\"\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pinv_wexog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wendog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wexog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hasconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m---> 64\u001b[0;31m                                       **kwargs)\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0;32m--> 633\u001b[0;31m                  **kwargs)\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# this has side-effects, attaches k_constant and const_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresettable_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m_handle_constant\u001b[0;34m(self, hasconst)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# Compute rank of augmented matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 augmented_exog = np.column_stack(\n\u001b[0;32m--> 174\u001b[0;31m                             (np.ones(self.exog.shape[0]), self.exog))\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0mrank_augm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_matrix_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_exog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mrank_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_matrix_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reg = build_ts_regressor(ts)\n",
    "eps = np.zeros_like(ts.values[7*SAMPS_DAY:])\n",
    "regressions = [None for i in range(SAMPS_DAY)]\n",
    "\n",
    "for c in range(25):\n",
    "    eps_reg = np.hstack([eps[:-7*SAMPS_DAY,None], eps[6*SAMPS_DAY:-SAMPS_DAY,None]])\n",
    "    for daily_time in range(SAMPS_DAY):\n",
    "        regressions[daily_time] = sm.OLS(\n",
    "                exog=np.hstack(\n",
    "                    [reg[7*SAMPS_DAY+daily_time::SAMPS_DAY],eps_reg[daily_time::SAMPS_DAY]]\n",
    "                ),\n",
    "                endog=ts.values[daily_time + 14*SAMPS_DAY::SAMPS_DAY]\n",
    "            ).fit()\n",
    "        eps[daily_time::SAMPS_DAY] = ts.values[daily_time + 7*SAMPS_DAY::SAMPS_DAY]\\\n",
    "            - regressions[daily_time].predict(\n",
    "                np.hstack([\n",
    "                        reg[daily_time::SAMPS_DAY],\n",
    "                        np.vstack([np.zeros([7*SAMPS_DAY,eps_reg.shape[1]]), eps_reg])[daily_time::SAMPS_DAY]\n",
    "                ])\n",
    "            )\n",
    "    if c % 10 == 0:\n",
    "        print(c, np.mean(np.abs(eps[7*SAMPS_DAY:]/ts.values[14*SAMPS_DAY:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressions[48].conf_int().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels import api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c_i in range(0,22):\n",
    "    lb = [regressions[i].conf_int()[c_i, 0] for i in range(SAMPS_DAY)]\n",
    "    ub = [regressions[i].conf_int()[c_i, 1] for i in range(SAMPS_DAY)]\n",
    "#     plt.fill_between(np.arange(SAMPS_DAY), lb,ub)\n",
    "#     plt.hlines(0, 0, 95)\n",
    "#     plt.show()\n",
    "# uncomment for plot of evolution of coefficients along the day\n",
    "\n",
    "# this plot is not similar at all to that of the paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acf should be more or less flat?\n",
    "\n",
    "# plot_acf(eps, lags=np.arange(0,22));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
