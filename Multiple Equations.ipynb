{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swissgrid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = swissgrid.grid_data.iloc[:,0].fillna(method='bfill')\n",
    "SAMPS_DAY = 24*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('data/weather_data_filtered.csv')\n",
    "weather['timestamp'] = pd.to_datetime(weather['utc_timestamp'])\n",
    "weather = weather[['timestamp', 'CH_temperature']].set_index('timestamp').sort_index()\n",
    "weather = weather.resample('1 H').first()\n",
    "weather = weather.tz_localize(None)\n",
    "weather = weather.resample('15 T').interpolate('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the two sequences\n",
    "ts = ts[:weather.index[-1]]\n",
    "weather = weather[ts.index[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ts.index\n",
    "# special days\n",
    "def get_holy(prov):\n",
    "    h = holidays.Switzerland(prov=prov)\n",
    "    return [day in h for day in days]\n",
    "holidays_cantons = pd.DataFrame(data = {prov:get_holy(prov) for prov in holidays.Switzerland.PROVINCES},\n",
    "             index = days)\n",
    "#add sundays (hurts MSE)\n",
    "# holidays_cantons = (holidays_cantons.T | (holidays_cantons.index.dayofweek == 6)).T\n",
    "\n",
    "cantons = pd.read_csv('data/cantons.csv').set_index('Code')\n",
    "#magic trick\n",
    "cantons['Population'] = cantons['Population'].str.extract('([^\\[]*)').iloc[:,0].str.split(',').str.join('').astype(np.intp)\n",
    "\n",
    "holiday_pop = holidays_cantons*cantons['Population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoregressive part\n",
    "\n",
    "The consumption $L_{hd}$ today at day $d$ and hour $h$ depends on $L_{h-1d}$, $L_{hd-1}$, $L_{hd-7}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ts_regressor(ts, fourier_order=4):\n",
    "    #interact annual pattern like (6)\n",
    "    week_lag_idx = np.arange(ts.size-SAMPS_DAY*7)\n",
    "    t = ((\n",
    "        ts.index[SAMPS_DAY*7:ts.size] - pd.datetime(year=ts.index[0].year, month=1, day=1)\n",
    "    ).total_seconds()//(60*24*60/SAMPS_DAY)).astype(np.intp)\n",
    "    samps_year = SAMPS_DAY*7*52\n",
    "    sins =  np.array([np.sin(2*q*np.pi*(t/samps_year)) for q in range(1, fourier_order+1)]).T\n",
    "    cosins =np.array([np.cos(2*q*np.pi*(t/samps_year)) for q in range(1, fourier_order+1)]).T\n",
    "    week_lagged_reg = ts.values[week_lag_idx,None]*np.hstack([np.ones((week_lag_idx.size,1)), sins, cosins])\n",
    "    \n",
    "    #interact daily indicators with daily lag (5)\n",
    "    week_day = ts.index[SAMPS_DAY*7:ts.size].dayofweek\n",
    "    I = np.eye(7)\n",
    "    week_day_indicators = np.array([I[i] for i in week_day])\n",
    "    day_lag_idx = np.arange(SAMPS_DAY*6, ts.size-SAMPS_DAY)\n",
    "    day_lagged_reg = ts.values[day_lag_idx,None]*week_day_indicators\n",
    "    \n",
    "    # hourly lag regressor (7)\n",
    "    hour_lag_idx = np.arange(SAMPS_DAY*7 - 1, ts.size-1)\n",
    "    hour_lagged_reg = ts.values[hour_lag_idx][:,None]\n",
    "    \n",
    "    #temperature\n",
    "    weather_reg = weather.values[SAMPS_DAY*7:ts.size]\n",
    "    \n",
    "    #special days\n",
    "    holiday_reg = holiday_pop.sum(axis=1).values[SAMPS_DAY*7:ts.size, None]\n",
    "    holiday_lagged_reg = holiday_pop.sum(axis=1).values[:ts.size - SAMPS_DAY*7,None]\n",
    "    \n",
    "    return np.hstack(\n",
    "        [\n",
    "            week_lagged_reg,\n",
    "            day_lagged_reg,\n",
    "            hour_lagged_reg,\n",
    "            weather_reg,\n",
    "            holiday_reg,\n",
    "            holiday_lagged_reg\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = build_ts_regressor(ts)\n",
    "lr = LinearRegression().fit(reg, ts.values[7*SAMPS_DAY:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013428251107830377"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE_triv = np.mean(np.abs((ts.values[7*SAMPS_DAY-1:-1] - ts.values[7*SAMPS_DAY:]))/ts.values[7*SAMPS_DAY:])\n",
    "MAPE_triv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01285939996303295"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE = np.mean(np.abs((lr.predict(reg) - ts.values[7*SAMPS_DAY:]))/ts.values[7*SAMPS_DAY:])\n",
    "MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average part\n",
    "\n",
    "We can now add a moving average component to the mix and see if our forecasting imporves. The moving average takes into account previous hour errors and previous week error.\n",
    "The estimation is done by applying the ordinary linear model, and treating residuals as estimated innovations, and iterating the least square estimation, and innovation estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.012861128884652464\n",
      "1 0.006131352722112417\n",
      "2 0.01218793396426801\n",
      "3 0.007354190132208505\n",
      "4 0.011657035501870517\n",
      "5 0.008094055598941696\n",
      "6 0.011263047348580007\n",
      "7 0.008525959288165845\n",
      "8 0.011013724173623438\n",
      "9 0.008783827920633988\n",
      "10 0.01085655438386978\n",
      "11 0.008946072964102627\n",
      "12 0.010737718725811371\n",
      "13 0.009080013801032218\n",
      "14 0.010633772619129244\n",
      "15 0.009208882152856295\n",
      "16 0.010532886637025628\n",
      "17 0.009327931791110257\n",
      "18 0.010439736953300282\n",
      "19 0.009431054572513869\n",
      "20 0.010358303805496866\n",
      "21 0.009513243363826532\n",
      "22 0.010290910840467194\n",
      "23 0.009577446624755933\n",
      "24 0.010239559604734116\n",
      "25 0.009628432047370796\n",
      "26 0.010195690198762332\n",
      "27 0.009670458233369244\n",
      "28 0.010158014492929506\n",
      "29 0.009706256685063747\n",
      "30 0.010126506388795711\n",
      "31 0.009737940699068293\n",
      "32 0.01009789576660453\n",
      "33 0.009765492065093329\n",
      "34 0.010072756187669061\n",
      "35 0.009789924349569533\n",
      "36 0.010051486213568802\n",
      "37 0.009810504018279622\n",
      "38 0.010033147321825501\n",
      "39 0.009827946100736154\n",
      "40 0.010017696292482716\n",
      "41 0.009843093893025293\n",
      "42 0.01000498160028771\n",
      "43 0.009855768641645703\n",
      "44 0.009993981559304031\n",
      "45 0.009866572338969605\n",
      "46 0.009984432159424808\n",
      "47 0.00987581054438166\n",
      "48 0.00997646650826809\n",
      "49 0.009883618381359757\n",
      "50 0.009969350896031246\n",
      "51 0.009890311913832304\n",
      "52 0.009963252235733808\n",
      "53 0.009896003816885478\n",
      "54 0.009958104248274448\n",
      "55 0.009900898313490846\n",
      "56 0.009953593667564533\n",
      "57 0.009904977675595852\n",
      "58 0.00994985080224572\n",
      "59 0.009908461793908996\n",
      "60 0.009946609692712166\n",
      "61 0.009911491740487296\n",
      "62 0.009943818000226328\n",
      "63 0.009913970967583665\n",
      "64 0.009941520529222108\n",
      "65 0.009916105643337792\n",
      "66 0.009939485436351926\n",
      "67 0.009917943730151176\n",
      "68 0.00993779257035202\n",
      "69 0.009919452432297566\n",
      "70 0.00993636554189278\n",
      "71 0.009920734586942611\n",
      "72 0.009935126397039497\n",
      "73 0.009921851243228341\n",
      "74 0.00993410939679209\n",
      "75 0.009922769270382279\n",
      "76 0.009933201063503084\n",
      "77 0.009923562720402561\n",
      "78 0.009932407457526809\n",
      "79 0.0099243111281626\n",
      "80 0.009931717495312615\n",
      "81 0.009924941894807601\n",
      "82 0.00993110269437098\n",
      "83 0.009925517654673062\n",
      "84 0.00993054118225199\n",
      "85 0.009926056401494906\n",
      "86 0.009930051845110541\n",
      "87 0.009926506168397803\n",
      "88 0.009929654281478845\n",
      "89 0.009926895182066305\n",
      "90 0.009929308138496266\n",
      "91 0.009927217772521719\n",
      "92 0.009929030257604096\n",
      "93 0.009927471841764575\n",
      "94 0.00992882423513121\n",
      "95 0.009927670247501097\n",
      "96 0.009928660707132692\n",
      "97 0.009927821259366938\n",
      "98 0.009928538889688155\n",
      "99 0.009927935610294165\n"
     ]
    }
   ],
   "source": [
    "reg = build_ts_regressor(ts)\n",
    "eps = np.zeros_like(ts.values[7*SAMPS_DAY:])\n",
    "# we drop an additional leading week so the least squares estimation is done\n",
    "# with all the estimated epsilons, previous week before included.\n",
    "for c in range(100):\n",
    "    eps_reg = np.hstack([eps[:-7*SAMPS_DAY,None], eps[6*SAMPS_DAY:-SAMPS_DAY,None]])\n",
    "    lr = LinearRegression().fit(np.hstack([reg[7*SAMPS_DAY:],eps_reg]), ts.values[14*SAMPS_DAY:])\n",
    "    eps = ts.values[7*SAMPS_DAY:] - lr.predict(np.hstack([reg, np.vstack([np.zeros([7*SAMPS_DAY,eps_reg.shape[1]]), eps_reg])]))\n",
    "    print(c, np.mean(np.abs(eps[7*SAMPS_DAY:]/ts.values[14*SAMPS_DAY:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Equations\n",
    "\n",
    "By changing the single regression into 96 individual parameter sets, one for each daily time, we are back to the multiple equations setting described in Clements, Hurn and Li."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.004430604714915216\n",
      "100 0.004310552310005237\n",
      "200 0.0043105523100036534\n",
      "300 0.0043105523100036135\n",
      "400 0.004310552310003565\n",
      "500 0.004310552310003626\n",
      "600 0.004310552310003822\n",
      "700 0.004310552310003665\n",
      "800 0.004310552310003729\n",
      "900 0.004310552310003775\n"
     ]
    }
   ],
   "source": [
    "reg = build_ts_regressor(ts)\n",
    "eps = np.zeros_like(ts.values[7*SAMPS_DAY:])\n",
    "regressions = [LinearRegression() for i in range(SAMPS_DAY)]\n",
    "\n",
    "for c in range(1000):\n",
    "    eps_reg = np.hstack([eps[:-7*SAMPS_DAY,None], eps[6*SAMPS_DAY:-SAMPS_DAY,None]])\n",
    "    for daily_time in range(SAMPS_DAY):\n",
    "        regressions[daily_time].fit(\n",
    "            np.hstack(\n",
    "                [reg[7*SAMPS_DAY+daily_time::SAMPS_DAY],eps_reg[daily_time::SAMPS_DAY]]\n",
    "            ),\n",
    "            ts.values[daily_time + 14*SAMPS_DAY::SAMPS_DAY]\n",
    "        )\n",
    "        eps[daily_time::SAMPS_DAY] = ts.values[daily_time + 7*SAMPS_DAY::SAMPS_DAY]\\\n",
    "            - regressions[daily_time].predict(\n",
    "                np.hstack([\n",
    "                        reg[daily_time::SAMPS_DAY],\n",
    "                        np.vstack([np.zeros([7*SAMPS_DAY,eps_reg.shape[1]]), eps_reg])[daily_time::SAMPS_DAY]\n",
    "                ])\n",
    "            )\n",
    "    if c % 100 == 0:\n",
    "        print(c, np.mean(np.abs(eps[7*SAMPS_DAY:]/ts.values[14*SAMPS_DAY:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels import api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c_i in [10,11,13,14,15,16]:\n",
    "#     plt.plot([regressions[i].coef_[12] - regressions[i].coef_[c_i] for i in range(SAMPS_DAY)]);\n",
    "# plt.legend(['monday','tuesday','thursday','friday','saturday','sunday'])\n",
    "\n",
    "# this plot is not similar at all to that of the paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acf should be more or less flat?\n",
    "\n",
    "# plot_acf(eps, lags=np.arange(0,22));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
